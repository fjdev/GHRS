#!/usr/bin/env python3
"""
GitHub Repository Sync (GHRS)
==============================

A professional tool for syncing GitHub repositories (particularly Terraform modules)
with version tracking and automated cleanup.

Features:
- Release-based syncing (latest or tagged)
- Version tracking with @version suffix
- Automatic file cleanup (keeps only essential TF files)
- GitHub App and PAT authentication
- Configurable organization defaults
- Robust error handling and logging

Requirements:
- Python 3.7+
- Git CLI
- GitHub credentials (App or PAT)
- PyJWT (optional, for GitHub App authentication)

Author: fjdev
License: MIT
Version: 1.0.0
"""

# Standard library imports
from __future__ import annotations
import concurrent.futures
import gzip
import json
import logging
import os
import shutil
import sys
import tempfile
import time
from abc import ABC, abstractmethod
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Any
from urllib.request import Request, urlopen
from urllib.error import HTTPError, URLError
import zipfile
import tarfile


__version__ = "1.0.0"
__author__ = "fjdev"


# Configuration
class SyncConfig:
    """Configuration constants for GHRS."""
    # Paths
    ROOT = Path(__file__).resolve().parent
    CONFIG_FILE = "modules.json"
    DEFAULT_DEST = "modules"
    MAX_WORKERS = int(os.environ.get("GHRS_MAX_WORKERS", "4"))
    HTTP_TIMEOUT = int(os.environ.get("GHRS_HTTP_TIMEOUT", "20"))
    
    # GitHub API
    GITHUB_API = "https://api.github.com"
    GITHUB_URL = "https://github.com"
    
    # Allowed files (all others will be removed)
    ALLOWED_FILES = {"main.tf", "outputs.tf", "README.md", "terraform.tf", "variables.tf"}
    
    # Defaults
    DEFAULT_MODULE_DIR = "."
    RETRY_ATTEMPTS = int(os.environ.get("GHRS_RETRY_ATTEMPTS", "3"))
    RETRY_BACKOFF_SECONDS = int(os.environ.get("GHRS_RETRY_BACKOFF_SECONDS", "1"))
    
    # Exit codes
    EXIT_CODE_SUCCESS = 0
    EXIT_CODE_ERROR = 1
    
    # Logging
    LOG_FORMAT = '%(asctime)s - %(levelname)s - %(message)s'
    LOG_DATE_FORMAT = '%Y-%m-%d %H:%M:%S'


# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format=SyncConfig.LOG_FORMAT,
    datefmt=SyncConfig.LOG_DATE_FORMAT
)
logger = logging.getLogger(__name__)


# Custom Exceptions
class SyncError(Exception):
    """Base exception for sync errors."""
    pass


class AuthenticationError(SyncError):
    """Raised when authentication fails."""
    pass


class DownloadError(SyncError):
    """Raised when download operations fail."""
    pass


class ExtractionError(SyncError):
    """Raised when extraction operations fail."""
    pass


class ConfigurationError(SyncError):
    """Raised when configuration is invalid."""
    pass


class GitOperationError(SyncError):
    """Raised when git operations fail."""
    pass


# Data Models
@dataclass
class ModuleConfig:
    """Configuration for a single module."""
    name: str
    repo: str
    mode: str = "release"
    tag: Optional[str] = None
    asset_name: Optional[str] = None
    module_dir: str = SyncConfig.DEFAULT_MODULE_DIR


@dataclass
class SyncResult:
    """Result of a sync operation."""
    name: str
    version: str
    mode: str
    success: bool
    error: Optional[str] = None


# Authentication
class GitHubAuthProvider(ABC):
    """Abstract base class for GitHub authentication providers."""
    
    @abstractmethod
    def get_token(self) -> Optional[str]:
        """Get authentication token."""
        pass


class GitHubAppAuthProvider(GitHubAuthProvider):
    """GitHub App authentication provider."""
    
    def get_token(self) -> Optional[str]:
        """Generate GitHub App installation access token."""
        app_id = os.environ.get("GITHUB_APP_ID")
        install_id = os.environ.get("GITHUB_APP_INSTALLATION_ID")
        private_key_path = os.environ.get("GITHUB_APP_PRIVATE_KEY_PATH")
        private_key_env = os.environ.get("GITHUB_APP_PRIVATE_KEY")
        
        if not all([app_id, install_id]) or not (private_key_path or private_key_env):
            return None
        
        try:
            import jwt
        except ImportError:
            logger.warning("PyJWT not installed. Run: pip install PyJWT")
            return None
        
        # Load private key
        if private_key_path and Path(private_key_path).exists():
            with open(private_key_path, "r") as f:
                private_key = f.read()
        elif private_key_env:
            private_key = private_key_env.replace("\\n", "\n")
        else:
            logger.warning("Private key not found")
            return None
        
        # Generate JWT
        now = int(time.time())
        payload = {
            "iat": now - 60,
            "exp": now + (10 * 60),
            "iss": app_id
        }
        jwt_token = jwt.encode(payload, private_key, algorithm="RS256")
        
        # Get installation access token
        url = f"{SyncConfig.GITHUB_API}/app/installations/{install_id}/access_tokens"
        headers = {
            "Authorization": f"Bearer {jwt_token}",
            "Accept": "application/vnd.github+json"
        }
        req = Request(url, headers=headers, method="POST")
        try:
            with urlopen(req) as r:
                response_data = decompress_response(r.read())
                data = json.loads(response_data.decode("utf-8"))
                return data.get("token")
        except (HTTPError, URLError) as e:
            raise AuthenticationError(f"Failed to get GitHub App token: {e}")


class PersonalAccessTokenAuthProvider(GitHubAuthProvider):
    """Personal Access Token authentication provider."""
    
    def get_token(self) -> Optional[str]:
        """Get PAT from environment."""
        return os.environ.get("GITHUB_TOKEN") or os.environ.get("GH_TOKEN")


class AuthenticationManager:
    """Manages authentication token retrieval."""
    
    def __init__(self):
        self.providers: List[GitHubAuthProvider] = [
            GitHubAppAuthProvider(),
            PersonalAccessTokenAuthProvider(),
        ]
    
    def get_token(self) -> Optional[str]:
        """Try each authentication provider in order."""
        for provider in self.providers:
            token = provider.get_token()
            if token:
                provider_name = provider.__class__.__name__.replace("AuthProvider", "")
                logger.info(f"Using {provider_name} authentication")
                return token
        
        logger.warning("No authentication configured - API rate limits may apply")
        return None


def ensure_clean_dir(path: Path) -> None:
    """Ensure directory exists and is empty."""
    if path.exists():
        shutil.rmtree(path)
    path.mkdir(parents=True, exist_ok=True)


def decompress_response(data: bytes) -> bytes:
    """Decompress gzip-encoded response data if needed."""
    # Check for gzip magic number (0x1f 0x8b)
    if len(data) >= 2 and data[0] == 0x1f and data[1] == 0x8b:
        return gzip.decompress(data)
    return data


def save_release_notes(dest_dir: Path, release: Dict[str, Any], repo: str, module_name: str) -> None:
    """Save release notes metadata to a file."""
    try:
        release_notes_path = dest_dir / "RELEASE_NOTES.md"
        
        # Extract release metadata
        tag = release.get("tag_name", "unknown")
        body = release.get("body", "")
        author = release.get("author", {})
        author_name = author.get("login", "unknown") if isinstance(author, dict) else str(author)
        published_at = release.get("published_at", "unknown")
        html_url = release.get("html_url", "")
        
        # Format release notes
        notes = f"""# Release Notes: {module_name} ({tag})

**Release Date:** {published_at}  
**Author:** {author_name}  
**GitHub Release:** [{tag}]({html_url})

## Changes

{body if body else "No release notes provided."}

---
*Generated by GHRS - GitHub Repository Sync*
"""
        
        with open(release_notes_path, "w") as f:
            f.write(notes)
        logger.debug(f"Saved release notes to {release_notes_path}")
    except Exception as e:
        logger.warning(f"Failed to save release notes: {e}")


def cleanup_unwanted_files(dest_dir: Path) -> None:
    """Remove all files except the allowed ones and RELEASE_NOTES.md."""
    allowed = SyncConfig.ALLOWED_FILES | {"RELEASE_NOTES.md"}
    for item in dest_dir.iterdir():
        if item.is_file() and item.name not in allowed:
            item.unlink()
            logger.debug(f"Removed: {item.name}")
        elif item.is_dir():
            shutil.rmtree(item)
            logger.debug(f"Removed directory: {item.name}")


# Downloader
class GitHubDownloader:
    """Handles downloading from GitHub."""
    
    def __init__(self, token: Optional[str] = None):
        self.token = token

    def _maybe_handle_rate_limit(self, err: HTTPError) -> bool:
        """Check for GitHub rate limit response and back off once."""
        remaining = err.headers.get("X-RateLimit-Remaining") if err.headers else None
        reset = err.headers.get("X-RateLimit-Reset") if err.headers else None
        if err.code == 403 and remaining == "0":
            wait = 3
            if reset and reset.isdigit():
                wait = max(1, min(30, int(reset) - int(time.time())))
            logger.warning(f"GitHub rate limit reached; retrying in {wait}s")
            time.sleep(wait)
            return True
        return False
    
    def download(self, url: str, dest: Path) -> None:
        """Download a file from URL to destination."""
        headers = {
            "User-Agent": "ghrs",
            "Accept-Encoding": "gzip",
        }
        if self.token:
            headers["Authorization"] = f"Bearer {self.token}"
        
        req = Request(url, headers=headers)
        for attempt in range(SyncConfig.RETRY_ATTEMPTS):
            try:
                with urlopen(req, timeout=SyncConfig.HTTP_TIMEOUT) as response, open(dest, "wb") as f:
                    shutil.copyfileobj(response, f)
                logger.debug(f"Downloaded: {url}")
                return
            except HTTPError as e:
                if self._maybe_handle_rate_limit(e):
                    continue
                if attempt < SyncConfig.RETRY_ATTEMPTS - 1:
                    time.sleep(SyncConfig.RETRY_BACKOFF_SECONDS * (attempt + 1))
                    continue
                raise DownloadError(f"Download failed: {url}\n{e}")
            except URLError as e:
                if attempt < SyncConfig.RETRY_ATTEMPTS - 1:
                    time.sleep(SyncConfig.RETRY_BACKOFF_SECONDS * (attempt + 1))
                    continue
                raise DownloadError(f"Download failed: {url}\n{e}")
    
    def get_release(self, repo: str, tag: Optional[str] = None) -> Dict[str, Any]:
        """Get release information from GitHub API."""
        if tag:
            url = f"{SyncConfig.GITHUB_API}/repos/{repo}/releases/tags/{tag}"
        else:
            url = f"{SyncConfig.GITHUB_API}/repos/{repo}/releases/latest"
        
        headers = {
            "User-Agent": "ghrs",
            "Accept": "application/vnd.github+json",
            "Accept-Encoding": "gzip",
        }
        if self.token:
            headers["Authorization"] = f"Bearer {self.token}"
        
        req = Request(url, headers=headers)
        for attempt in range(SyncConfig.RETRY_ATTEMPTS):
            try:
                with urlopen(req, timeout=SyncConfig.HTTP_TIMEOUT) as response:
                    response_data = decompress_response(response.read())
                    return json.loads(response_data.decode("utf-8"))
            except HTTPError as e:
                if self._maybe_handle_rate_limit(e):
                    continue
                if attempt < SyncConfig.RETRY_ATTEMPTS - 1:
                    time.sleep(SyncConfig.RETRY_BACKOFF_SECONDS * (attempt + 1))
                    continue
                raise DownloadError(f"Failed to get release: {url}\n{e}")
            except URLError as e:
                if attempt < SyncConfig.RETRY_ATTEMPTS - 1:
                    time.sleep(SyncConfig.RETRY_BACKOFF_SECONDS * (attempt + 1))
                    continue
                raise DownloadError(f"Failed to get release: {url}\n{e}")


# Extractor
class ArchiveExtractor:
    """Handles archive extraction."""
    
    @staticmethod
    def extract(archive_path: Path, dest_dir: Path, subdir: Optional[str] = None) -> None:
        """Extract archive to destination directory."""
        ensure_clean_dir(dest_dir)

        def _is_within(base: Path, target: Path) -> bool:
            try:
                target.relative_to(base)
                return True
            except ValueError:
                return False

        try:
            # Determine archive type from extension
            is_zip = archive_path.name.endswith(".zip")
            is_targz = archive_path.name.endswith((".tar.gz", ".tgz"))
            
            if is_zip:
                with zipfile.ZipFile(archive_path) as z:
                    for member in z.infolist():
                        target = (dest_dir / member.filename).resolve()
                        if not _is_within(dest_dir.resolve(), target):
                            raise ExtractionError("Unsafe path in zip archive")
                    z.extractall(dest_dir)
            elif is_targz:
                with tarfile.open(archive_path, "r:gz") as t:
                    for member in t.getmembers():
                        target = (dest_dir / member.name).resolve()
                        if not _is_within(dest_dir.resolve(), target):
                            raise ExtractionError("Unsafe path in tar archive")
                    t.extractall(dest_dir)
            else:
                # Assume uncompressed tar
                with tarfile.open(archive_path, "r") as t:
                    for member in t.getmembers():
                        target = (dest_dir / member.name).resolve()
                        if not _is_within(dest_dir.resolve(), target):
                            raise ExtractionError("Unsafe path in tar archive")
                    t.extractall(dest_dir)
        except (zipfile.BadZipFile, tarfile.TarError) as e:
            raise ExtractionError(f"Failed to extract archive: {e}")
        
        # Handle GitHub release archives which wrap everything in a root directory
        roots = [p for p in dest_dir.iterdir() if p.is_dir()]
        if len(roots) == 1 and not subdir:
            # Single root directory - unwrap it (GitHub tarball/zipball case)
            root = roots[0]
            tmp = Path(tempfile.mkdtemp(prefix="ghrs_unwrap_"))
            
            try:
                for item in root.iterdir():
                    if item.is_dir():
                        shutil.copytree(item, tmp / item.name, dirs_exist_ok=True)
                    else:
                        shutil.copy2(item, tmp / item.name)
                
                ensure_clean_dir(dest_dir)
                shutil.copytree(tmp, dest_dir, dirs_exist_ok=True)
            finally:
                shutil.rmtree(tmp, ignore_errors=True)
        
        if subdir:
            roots = [p for p in dest_dir.iterdir() if p.is_dir()]
            if not roots:
                raise ExtractionError(f"No directories found in archive")
            
            src = (roots[0] / subdir).resolve()
            if not src.exists():
                raise ExtractionError(f"Subdir '{subdir}' not found in archive")
            
            tmp = Path(tempfile.mkdtemp(prefix="ghrs_subdir_"))
            try:
                for item in src.iterdir():
                    if item.is_dir():
                        shutil.copytree(item, tmp / item.name, dirs_exist_ok=True)
                    else:
                        shutil.copy2(item, tmp / item.name)
                
                ensure_clean_dir(dest_dir)
                shutil.copytree(tmp, dest_dir, dirs_exist_ok=True)
            finally:
                shutil.rmtree(tmp, ignore_errors=True)


# Sync Strategies
class SyncStrategy(ABC):
    """Abstract base class for sync strategies."""
    
    @abstractmethod
    def sync(self, module: ModuleConfig, dest_root: Path) -> SyncResult:
        """Sync a module."""
        pass


class ReleaseSyncStrategy(SyncStrategy):
    """Sync from GitHub releases."""
    
    def __init__(self, downloader: GitHubDownloader):
        self.downloader = downloader
    
    def sync(self, module: ModuleConfig, dest_root: Path) -> SyncResult:
        """Sync module from GitHub release."""
        try:
            logger.info(f"Syncing {module.name} from release...")
            
            # Get release info
            release = self.downloader.get_release(module.repo, module.tag)
            version = release.get("tag_name") or release.get("tag") or "latest"
            
            # Find download URL
            dl_url = None
            if module.asset_name and release.get("assets"):
                for asset in release["assets"]:
                    if asset.get("name") == module.asset_name:
                        dl_url = asset.get("browser_download_url")
                        break
            
            if not dl_url:
                dl_url = release.get("tarball_url") or release.get("zipball_url")
            
            # Download and extract
            tmp = Path(tempfile.mkdtemp(prefix=f"modsync_{module.name}_"))
            try:
                # Determine archive filename and extension based on URL
                if module.asset_name:
                    archive = tmp / module.asset_name
                elif "tarball" in dl_url:
                    archive = tmp / "source.tar.gz"
                else:
                    archive = tmp / "source.zip"
                self.downloader.download(dl_url, archive)
                
                versioned_name = f"{module.name}@{version}"
                dest = dest_root / versioned_name
                
                ArchiveExtractor.extract(
                    archive,
                    dest,
                    module.module_dir if module.module_dir != "." else None
                )
                
                save_release_notes(dest, release, module.repo, module.name)
                cleanup_unwanted_files(dest)
                
                logger.info(f"✓ Synced: {module.name} ({version})")
                return SyncResult(module.name, version, "release", True)
                
            finally:
                shutil.rmtree(tmp, ignore_errors=True)
                
        except Exception as e:
            logger.error(f"✗ Failed to sync {module.name}: {e}")
            return SyncResult(module.name, "unknown", "release", False, str(e))
# Configuration Parser
class ConfigParser:
    """Parse module configuration."""
    
    @staticmethod
    def parse_module(entry: str | dict, default_org: Optional[str]) -> ModuleConfig:
        """Parse module entry from string or dict format."""
        if isinstance(entry, str):
            # Format must be "owner/repo-name"
            if "/" not in entry:
                if not default_org:
                    raise ConfigurationError(
                        f"Module '{entry}' missing organization. "
                        "Either specify 'organization' in config or use 'owner/repo' format."
                    )
                repo = f"{default_org}/{entry}"
            else:
                repo = entry
            name = repo.split("/")[-1]
            return ModuleConfig(name=name, repo=repo)
        else:
            # Dict format; ignore legacy 'ref' field
            cfg = dict(entry)
            cfg.pop("ref", None)
            return ModuleConfig(**cfg)
    
    @staticmethod
    def load_config(config_path: Path) -> Dict[str, Any]:
        """Load configuration from JSON file."""
        if not config_path.exists():
            raise ConfigurationError(f"Config not found: {config_path}")
        
        try:
            with open(config_path) as f:
                cfg = json.load(f)
        except json.JSONDecodeError as e:
            raise ConfigurationError(f"Invalid JSON in config: {e}")

        modules = cfg.get("modules", [])
        if not isinstance(modules, list) or not modules:
            raise ConfigurationError("Config 'modules' must be a non-empty list")

        return cfg


# Main Application
class ModuleSyncApplication:
    """Main module sync application."""
    
    def __init__(self, config_path: Path):
        self.config_path = config_path
        self.auth_manager = AuthenticationManager()
    
    def run(self) -> int:
        """Run the sync application."""
        try:
            # Load configuration
            config = ConfigParser.load_config(self.config_path)
            
            # Setup paths
            dest_root = SyncConfig.ROOT / config.get("destination_root", SyncConfig.DEFAULT_DEST)
            dest_root.mkdir(parents=True, exist_ok=True)
            
            default_org = config.get("organization")
            
            # Get authentication
            token = self.auth_manager.get_token()
            
            # Initialize sync strategies
            downloader = GitHubDownloader(token)
            strategies = {
                "release": ReleaseSyncStrategy(downloader),
            }
            
            # Sync each module (parallel)
            results: List[SyncResult] = []
            modules = config.get("modules", [])
            max_workers = min(SyncConfig.MAX_WORKERS, max(1, len(modules)))
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = []
                for entry in modules:
                    module = ConfigParser.parse_module(entry, default_org)
                    strategy = strategies.get(module.mode.lower())

                    if not strategy:
                        logger.error(
                            f"Unsupported mode '{module.mode}' for module '{module.name}'. "
                            "Only 'release' is allowed."
                        )
                        results.append(
                            SyncResult(module.name, "unknown", module.mode, False, "Invalid mode (release-only)")
                        )
                        continue

                    futures.append((module, executor.submit(strategy.sync, module, dest_root)))

                for module, future in futures:
                    try:
                        results.append(future.result())
                    except Exception as e:
                        logger.error(f"✗ Failed to sync {module.name}: {e}")
                        results.append(SyncResult(module.name, "unknown", module.mode, False, str(e)))
            
            # Summary
            successful = sum(1 for r in results if r.success)
            failed = len(results) - successful

            if failed:
                logger.error("Failed modules:")
                for r in results:
                    if not r.success:
                        logger.error(f"- {r.name} (mode={r.mode}, version={r.version}): {r.error}")
            
            logger.info(f"\n{'='*60}")
            logger.info(f"✓ Sync complete: {successful} successful, {failed} failed")
            logger.info(f"  Modules synced to: {dest_root}")
            logger.info(f"{'='*60}")
            
            return SyncConfig.EXIT_CODE_SUCCESS if failed == 0 else SyncConfig.EXIT_CODE_ERROR
            
        except ConfigurationError as e:
            logger.error(f"Configuration error: {e}")
            return SyncConfig.EXIT_CODE_ERROR
        except AuthenticationError as e:
            logger.error(f"Authentication error: {e}")
            return SyncConfig.EXIT_CODE_ERROR
        except Exception as e:
            logger.error(f"Unexpected error: {e}")
            logger.debug("", exc_info=True)
            return SyncConfig.EXIT_CODE_ERROR


def main() -> int:
    """Main entry point."""
    config_path = SyncConfig.ROOT / SyncConfig.CONFIG_FILE
    app = ModuleSyncApplication(config_path)
    return app.run()


if __name__ == "__main__":
    sys.exit(main())
